"""
End-to-End Test of Bidirectional Flow using a Runner/Wrapper approach.

This test demonstrates the complete bidirectional flow using real climate risk data:
1. Ingestion: Climate risk document → PatternAwareRAG → Vector-Tonic
2. Retrieval: Vector-Tonic → PatternAwareRAG

The test uses a wrapper/runner approach to isolate the core bidirectional flow logic.
"""

import asyncio
import logging
import os
import sys
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime
import uuid
from enum import Enum
from dataclasses import dataclass

# Add project root to Python path
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Define window states
class WindowState(Enum):
    CLOSED = "CLOSED"
    OPENING = "OPENING"
    OPEN = "OPEN"
    CLOSING = "CLOSING"

# Define direction types
class Direction(Enum):
    INGESTION = "ingestion"  # RAG → Vector-Tonic
    RETRIEVAL = "retrieval"  # Vector-Tonic → RAG
    BIDIRECTIONAL = "bidirectional"

# Define event model
@dataclass
class Event:
    type: str
    data: Dict[str, Any]
    source: str
    id: str = None
    
    @staticmethod
    def create(type: str, data: Dict[str, Any], source: str):
        return Event(
            type=type,
            data=data,
            source=source,
            id=str(uuid.uuid4())
        )

# Define pattern model
@dataclass
class Pattern:
    id: str
    base_concept: str
    creator_id: str
    weight: float = 1.0
    confidence: float = 0.8
    uncertainty: float = 0.2
    coherence: float = 0.7
    phase_stability: float = 0.6
    signal_strength: float = 0.8
    properties: Dict[str, Any] = None
    metrics: Dict[str, float] = None
    state: str = "ACTIVE"
    
    def __post_init__(self):
        if self.properties is None:
            self.properties = {}
        if self.metrics is None:
            self.metrics = {
                "coherence": self.coherence,
                "stability": self.phase_stability,
                "density": self.signal_strength
            }

# Define event bus
class LocalEventBus:
    """Simple event bus implementation for local event handling."""
    
    def __init__(self):
        """Initialize the event bus."""
        self.subscribers = {}
        self.processed_events = set()
    
    def subscribe(self, event_type: str, handler):
        """Subscribe to an event type.
        
        Args:
            event_type: Type of event to subscribe to
            handler: Handler function to call when event is published
        """
        if event_type not in self.subscribers:
            self.subscribers[event_type] = []
        self.subscribers[event_type].append(handler)
    
    def publish(self, event: Event):
        """Publish an event.
        
        Args:
            event: Event to publish
        """
        # Prevent duplicate processing
        if event.id in self.processed_events:
            return
        
        self.processed_events.add(event.id)
        
        # Call handlers
        if event.type in self.subscribers:
            for handler in self.subscribers[event.type]:
                handler(event)

# State change buffer for preventing feedback loops
class StateChangeBuffer:
    """Buffer for managing state changes to prevent feedback loops."""
    
    def __init__(self, buffer_size: int = 50, cooldown_period: float = 0.5):
        """Initialize the state change buffer.
        
        Args:
            buffer_size: Maximum number of recent changes to track
            cooldown_period: Minimum time (in seconds) between similar changes
        """
        self.recent_changes = []
        self.buffer_size = buffer_size
        self.cooldown_period = cooldown_period
    
    def should_propagate(self, entity_id: str, change_type: str) -> bool:
        """Determine if a change should be propagated.
        
        Args:
            entity_id: ID of the entity being changed
            change_type: Type of change being made
            
        Returns:
            True if the change should be propagated, False otherwise
        """
        # Check if similar change was recently processed
        now = datetime.now()
        for change in self.recent_changes:
            if (change["entity_id"] == entity_id and 
                change["change_type"] == change_type and
                (now - change["timestamp"]).total_seconds() < self.cooldown_period):
                return False
        
        # Add change to buffer
        self.recent_changes.append({
            "entity_id": entity_id,
            "change_type": change_type,
            "timestamp": now
        })
        
        # Trim buffer if needed
        if len(self.recent_changes) > self.buffer_size:
            self.recent_changes = self.recent_changes[-self.buffer_size:]
        
        return True

# Direction-aware event bus
class DirectionalEventBus:
    """Event bus with direction awareness for bidirectional communication."""
    
    def __init__(self, event_bus):
        """Initialize the directional event bus.
        
        Args:
            event_bus: The underlying event bus to wrap
        """
        self.event_bus = event_bus
        self.processed_event_ids = set()
    
    def publish(self, event_name: str, data: Dict[str, Any], direction: str = "bidirectional"):
        """Publish an event with direction awareness.
        
        Args:
            event_name: Name of the event to publish
            data: Event data
            direction: Direction of the event (ingestion, retrieval, or bidirectional)
        """
        # Add direction to data
        event_data = data.copy()
        event_data["direction"] = direction
        
        # Create and publish event
        event = Event.create(
            type=event_name,
            data=event_data,
            source="directional_event_bus"
        )
        
        self.event_bus.publish(event)
    
    def subscribe(self, event_name: str, handler, metadata: Optional[Dict[str, Any]] = None):
        """Subscribe to an event with direction awareness.
        
        Args:
            event_name: Name of the event to subscribe to
            handler: Handler function to call when the event is published
            metadata: Optional metadata for the subscription, including direction_filter
        """
        if metadata is None:
            metadata = {}
        
        direction_filter = metadata.get("direction_filter")
        
        # Create direction-filtered handler if needed
        if direction_filter:
            def direction_filtered_handler(event):
                event_direction = event.data.get("direction", "bidirectional")
                if event_direction == direction_filter or event_direction == "bidirectional":
                    handler(event)
            
            self.event_bus.subscribe(event_name, direction_filtered_handler)
        else:
            self.event_bus.subscribe(event_name, handler)

# Bidirectional flow manager
class BidirectionalFlowManager:
    """Manager for bidirectional flow between PatternAwareRAG and vector-tonic system."""
    
    def __init__(self, event_bus):
        """Initialize the bidirectional flow manager.
        
        Args:
            event_bus: The event bus to use for communication
        """
        self.event_bus = DirectionalEventBus(event_bus)
        self.state_change_buffer = StateChangeBuffer()
        self.coherence_threshold = 0.3
        self.constructive_dissonance_allowance = 0.1
    
    def should_process_field_change(self, event_data: Dict[str, Any], current_coherence: float) -> bool:
        """Determine if a field change should be processed based on coherence.
        
        This implements coherence-based filtering to prevent processing changes
        that would reduce system coherence below an acceptable threshold.
        
        Args:
            event_data: Event data containing the change
            current_coherence: Current coherence level of the system
            
        Returns:
            True if the change should be processed, False otherwise
        """
        # Extract field and change info
        field_id = event_data.get("field_id")
        state = event_data.get("state", {})
        
        # Check if change should be propagated based on recent changes
        if not self.state_change_buffer.should_propagate(field_id, "field_state_update"):
            logger.info(f"Field change for {field_id} blocked due to recent similar change")
            return False
        
        # Get coherence from state
        change_coherence = state.get("coherence", 0.0)
        
        # Allow changes that increase coherence
        if change_coherence >= current_coherence:
            return True
        
        # Block changes that would reduce coherence below threshold
        if change_coherence < self.coherence_threshold:
            logger.info(f"Field change for {field_id} blocked due to low coherence: {change_coherence}")
            return False
        
        # Allow constructive dissonance within allowance
        coherence_delta = current_coherence - change_coherence
        if coherence_delta <= self.constructive_dissonance_allowance:
            logger.info(f"Field change for {field_id} allowed as constructive dissonance: {coherence_delta}")
            return True
        
        logger.info(f"Field change for {field_id} blocked due to excessive coherence drop: {coherence_delta}")
        return False
    
    def map_window_state(self, window_state: str) -> str:
        """Map vector-tonic window state to learning window state.
        
        Args:
            window_state: Vector-tonic window state
            
        Returns:
            Mapped learning window state
        """
        # Direct mapping for this simplified implementation
        return window_state

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Vector-Tonic System Wrapper (simplified for testing)
class VectorTonicSystemWrapper:
    """Simplified Vector-Tonic System for testing bidirectional flow."""
    
    def __init__(self, event_bus):
        """Initialize the Vector-Tonic System."""
        self.event_bus = event_bus
        self.patterns = {}
        self.field_states = {}
        self.window_states = {}
        
        # Subscribe to pattern events from RAG
        self.event_bus.subscribe("pattern.detected", self._on_pattern_detected)
        
    def _on_pattern_detected(self, event):
        """Handle pattern detected events from RAG."""
        event_data = event.data
        direction = event_data.get("direction")
        
        # Only process events in the ingestion direction (RAG → Vector-Tonic)
        if direction == "ingestion":
            pattern = event_data.get("pattern")
            pattern_id = event_data.get("pattern_id")
            
            logger.info(f"Vector-Tonic received pattern from RAG: {pattern_id}")
            
            # Store the pattern
            self.patterns[pattern_id] = pattern
            
            # Process the pattern and update field state
            self._process_pattern(pattern)
    
    def _process_pattern(self, pattern):
        """Process a pattern and update field state with topological-temporal processing.
        
        Args:
            pattern: Pattern to process
        """
        # Extract field from pattern
        field_id = f"{pattern.base_concept}_field"
        
        # Calculate semantic potential metrics
        semantic_potential = self._calculate_semantic_potential(pattern)
        
        # Calculate topological metrics
        topology_metrics = self._calculate_topology_metrics(pattern)
        
        # Create a more sophisticated field state with topological-temporal dimensions
        field_state = {
            # Semantic Space
            "coherence": pattern.coherence,
            "density": pattern.signal_strength,
            "stability": pattern.phase_stability,
            
            # Statistical Space
            "emergence_rate": semantic_potential["emergence_rate"],
            "transition_probability": semantic_potential["transition_probability"],
            "pattern_density": semantic_potential["pattern_density"],
            
            # Correlated Field
            "gradient_vectors": semantic_potential["gradient_vectors"],
            "field_curvature": semantic_potential["field_curvature"],
            "potential_energy": semantic_potential["potential_energy"],
            
            # Topological Space
            "connectivity": topology_metrics["connectivity"],
            "centrality": topology_metrics["centrality"],
            "manifold_curvature": topology_metrics["manifold_curvature"],
            
            # Concept-Predicate Relationships
            "co_resonance_field": self._calculate_co_resonance(pattern),
            "intentionality_vectors": self._calculate_intentionality_vectors(pattern),
            
            # Cross-dimensional metrics
            "cross_paths": self._calculate_cross_paths(pattern),
            "back_pressure": self._calculate_back_pressure(pattern),
            "constructive_dissonance": self._calculate_constructive_dissonance(pattern)
        }
        
        # Update field state
        self._update_field_state(field_id, field_state)
        
        # Process the pattern for pattern evolution
        pattern_id = pattern.id
        self._process_pattern_evolution(pattern_id, pattern)
    
    def _update_field_state(self, field_id, field_state):
        """Update field state and notify RAG.
        
        Args:
            field_id: ID of the field to update
            field_state: New field state
        """
        # Store field state
        self.field_states[field_id] = field_state
        
        # Publish field state update in retrieval direction (Vector-Tonic → RAG)
        self.event_bus.publish(Event.create(
            type="field.state.updated",
            data={
                "field_id": field_id,
                "state": field_state,
                "direction": Direction.RETRIEVAL.value
            },
            source="vector_tonic"
        ))
        
{{ ... }}
            if new_state == WindowState.OPENING.value:
                self._handle_window_opening(window_id)
            elif new_state == WindowState.OPEN.value:
                self._handle_window_open(window_id)
            elif new_state == WindowState.CLOSING.value:
                self._handle_window_closing(window_id)
            elif new_state == WindowState.CLOSED.value:
                self._handle_window_closed(window_id)
    
    def _handle_window_opening(self, window_id):
        """Handle window OPENING state - this is where pattern emergence begins.
        
        This is a critical phase where the system prepares for pattern emergence
{{ ... }}
        and implements weeding characteristics to filter out noise and focus on
        meaningful patterns.
        
        Args:
            window_id: ID of the window being opened
        """
        logger.info(f"RAG handling OPENING state for window {window_id}")
        logger.info("  - Initializing semantic potential field")
        logger.info("  - Activating pattern emergence detection")
        
        # Simulate semantic potential calculation during window opening
        logger.info("  - Beginning weeding process:")
        logger.info("    * Establishing coherence threshold boundaries")
        logger.info("    * Initializing constructive dissonance allowance")
        logger.info("    * Setting up feedback loop prevention mechanisms")
        
        # Simulate the weeding characteristics evaluation
        weeding_metrics = {
            "noise_threshold": 0.25,
            "signal_amplification": 0.65,
            "coherence_boundary": self.bidirectional_flow_manager.coherence_threshold,
            "dissonance_allowance": self.bidirectional_flow_manager.constructive_dissonance_allowance,
            "emergence_sensitivity": 0.7,
            "pattern_density_threshold": 0.4
        }
        
        logger.info("  - Weeding characteristics configured:")
        for metric, value in weeding_metrics.items():
            logger.info(f"    * {metric}: {value:.4f}")
        
        logger.info("  - Preparing topological space for pattern emergence")
        logger.info("  - Initializing co-resonance field mapping")
        logger.info("  - Setting up intentionality vector detection")
    
    def _handle_window_open(self, window_id):
        """Handle window OPEN state - full pattern processing occurs.
        
        Args:
            window_id: ID of the window that is now open
        """
        logger.info(f"RAG handling OPEN state for window {window_id}")
        logger.info("  - Pattern processing fully activated")
        logger.info("  - Co-evolution dynamics enabled")
        logger.info("  - Bidirectional flow at maximum capacity")
    
    def _handle_window_closing(self, window_id):
        """Handle window CLOSING state - begin consolidating patterns.
        
        Args:
            window_id: ID of the window that is closing
        """
        logger.info(f"RAG handling CLOSING state for window {window_id}")
        logger.info("  - Beginning pattern consolidation")
        logger.info("  - Calculating final semantic potential")
        logger.info("  - Preparing to store evolved patterns")
    
    def _handle_window_closed(self, window_id):
        """Handle window CLOSED state - finalize pattern storage.
        
        Args:
            window_id: ID of the window that is now closed
        """
        logger.info(f"RAG handling CLOSED state for window {window_id}")
        logger.info("  - Pattern evolution cycle completed")
        logger.info("  - Semantic field stabilized")
        logger.info("  - Bidirectional flow paused")
    
    def _on_pattern_detected(self, event):
        """Handle pattern detected events.
        
        Args:
            event: Pattern detected event
        """
        event_data = event.data
        direction = event_data.get("direction")
        
        # Only process events in the retrieval direction (Vector-Tonic → RAG)
        if direction == Direction.RETRIEVAL.value:
            pattern_id = event_data.get("pattern_id")
            pattern = event_data.get("pattern")
            
            logger.info(f"RAG received evolved pattern from Vector-Tonic: {pattern_id}")
            
            # Update pattern
            self.patterns[pattern_id] = pattern

# E2E Test Class
class BidirectionalFlowE2ETest:
    """End-to-End test for bidirectional flow between PatternAwareRAG and Vector-Tonic."""
    
    def __init__(self):
        """Initialize the test environment."""
        # Create shared event bus
        self.event_bus = LocalEventBus()
        
        # Create PatternAwareRAG wrapper
        self.rag = PatternAwareRAGWrapper(self.event_bus)
        
        # Create Vector-Tonic System wrapper
        self.vector_tonic = VectorTonicSystemWrapper(self.event_bus)
        
        # Create system health monitor
        self.health_monitor = SystemHealthMonitor(self.event_bus)
        
        # Track events for validation
        self.pattern_events = []
        self.field_state_events = []
        self.window_state_events = []
        
        # Subscribe to events for tracking
        self.event_bus.subscribe("pattern.detected", self._on_pattern_detected)
        self.event_bus.subscribe("field.state.updated", self._on_field_state_updated)
        self.event_bus.subscribe("window.state.changed", self._on_window_state_changed)
    
    def _on_pattern_detected(self, event):
        """Track pattern events."""
        self.pattern_events.append(event)
    
    def _on_field_state_updated(self, event):
        """Track field state events."""
        self.field_state_events.append(event)
    
    def _on_window_state_changed(self, event):
        """Track window state events."""
        self.window_state_events.append(event)
    
    async def load_climate_risk_document(self):
        """Load climate risk document."""
        logger.info("Loading Martha's Vineyard climate risk document...")
        
        climate_risk_path = project_root / "data" / "climate_risk" / "climate_risk_marthas_vineyard.txt"
        
        # Create directory if it doesn't exist
        os.makedirs(climate_risk_path.parent, exist_ok=True)
        
        # If the file doesn't exist, create a sample climate risk document
        if not climate_risk_path.exists():
            logger.info("Climate risk document not found, creating sample document...")
            sample_text = """
            Climate Risk Assessment for Martha's Vineyard
            
            Executive Summary:
            Martha's Vineyard faces significant climate risks in the coming decades. As an island community,
            it is particularly vulnerable to sea level rise, coastal erosion, and increasing storm intensity.
            This assessment outlines key vulnerabilities and potential adaptation strategies.
            
            Key Climate Risks:
            1. Sea Level Rise: Projected 1-3 feet by 2050, threatening low-lying coastal areas
            2. Coastal Erosion: Accelerating loss of beaches and bluffs, especially on south-facing shores
            3. Storm Surge: Increased frequency and intensity of coastal flooding during storms
            4. Extreme Weather: More frequent and intense precipitation events and hurricanes
            5. Drought: Extended dry periods affecting freshwater availability and agriculture
            
            Vulnerable Areas:
            - Coastal properties in Oak Bluffs, Edgartown, and Chilmark
            - Critical infrastructure including ferry terminals and coastal roads
            - Freshwater aquifers vulnerable to saltwater intrusion
            - Agricultural lands facing changing growing conditions
            
            Adaptation Strategies:
            - Managed retreat from highest-risk coastal zones
            - Green infrastructure for stormwater management
            - Enhanced building codes for flood and wind resilience
            - Ecosystem-based adaptation to protect natural buffers
            - Community resilience planning and emergency preparedness
            
            This assessment emphasizes the need for immediate action to enhance island resilience
            while preserving the unique character and natural resources of Martha's Vineyard.
            """
            
            with open(climate_risk_path, "w") as f:
                f.write(sample_text)
        
        # Read the document
        with open(climate_risk_path, "r") as f:
            climate_risk_doc = f.read()
            
        return climate_risk_doc
    
    async def run_e2e_test(self):
        """Run the end-to-end test."""
        logger.info("Starting E2E test of bidirectional flow...")
        
        # Step 1: Load climate risk document
        climate_risk_doc = await self.load_climate_risk_document()
        logger.info(f"Loaded document with {len(climate_risk_doc)} characters")
        
        # Step 2: Vector-Tonic opens a learning window
        window_id = "climate_risk_window"
        await self.vector_tonic.open_learning_window(window_id)
        
        # Step 3: Process document through PatternAwareRAG
        logger.info("Processing document through PatternAwareRAG...")
        context = {"coherence_level": 0.8}
        
        # Process document (RAG → Vector-Tonic)
        self.rag.process_document(climate_risk_doc, context)
        
        # Step 5: Filter patterns by direction
        ingestion_patterns = [e for e in self.pattern_events 
                            if e.data.get("direction") == Direction.INGESTION.value]
        retrieval_patterns = [e for e in self.pattern_events 
                            if e.data.get("direction") == Direction.RETRIEVAL.value]
        
        logger.info(f"Detected {len(ingestion_patterns)} patterns in ingestion direction")
        logger.info(f"Detected {len(retrieval_patterns)} patterns in retrieval direction")
        
        # Step 6: Validate bidirectional pattern flow
        assert len(ingestion_patterns) > 0, "No patterns detected in ingestion direction"
        assert len(retrieval_patterns) > 0, "No patterns detected in retrieval direction"
        
        # Step 7: Validate field state updates
        logger.info(f"Received {len(self.field_state_events)} field state updates")
        assert len(self.field_state_events) > 0, "No field state updates received"
        
        # Step 8: Vector-Tonic closes the learning window
        await self.vector_tonic.close_learning_window(window_id)
        
        # Step 9: Validate window state changes
        logger.info(f"Received {len(self.window_state_events)} window state changes")
        assert len(self.window_state_events) > 0, "No window state changes received"
        
        logger.info("Generating system health report...")
        self.health_monitor.log_health_report()
        
        # Step 11: Validate system health metrics
        health_metrics = self.health_monitor.calculate_health_metrics()
        logger.info(f"System health score: {health_metrics['health_score']:.2f}/100")
        logger.info(f"Feedback loop risk: {health_metrics['feedback_loop_risk']:.2f}")
        
        # Validate health metrics
        assert health_metrics["health_score"] > 0, "System health score should be positive"
        assert health_metrics["feedback_loop_risk"] < 0.5, "Feedback loop risk should be moderate or low"
        
        # Step 12: Validate bidirectional flow
        logger.info("Validating bidirectional flow...")
        
        # Analyze differential between ingestion and retrieval
        logger.info("\nAnalyzing ingestion-retrieval differential for system health...")
        
        # Calculate average coherence improvement
        coherence_improvements = []
        for diff in self.health_monitor.pattern_coherence_diffs:
            coherence_improvements.append(diff["diff"])
            
        if coherence_improvements:
            avg_improvement = sum(coherence_improvements) / len(coherence_improvements)
            logger.info(f"Average coherence improvement: {avg_improvement:.4f}")
            logger.info(f"This indicates the system's ability to evolve patterns effectively")
        
        # Analyze response times
        if self.health_monitor.response_times:
            avg_response = sum(self.health_monitor.response_times) / len(self.health_monitor.response_times)
            logger.info(f"Average response time: {avg_response:.4f} seconds")
            logger.info(f"This measures the system's processing efficiency")
        
        # Analyze field state stability
        for field_id, states in self.health_monitor.field_state_diffs.items():
            if len(states) > 1:
                coherence_values = [state["coherence"] for state in states]
                stability_values = [state["stability"] for state in states]
                
                logger.info(f"Field {field_id} stability analysis:")
                logger.info(f"  - Final coherence: {coherence_values[-1]:.4f}")
                logger.info(f"  - Coherence change: {coherence_values[-1] - coherence_values[0]:.4f}")
                logger.info(f"  - Final stability: {stability_values[-1]:.4f}")
        
        logger.info("E2E test completed successfully!")

# System Health Monitor
class SystemHealthMonitor:
    """Monitor for tracking system health metrics based on bidirectional flow differentials.
    
    This class analyzes the differential between ingestion (RAG → vector-tonic) and
    retrieval (vector-tonic → RAG) to detect system health issues and calculate
    key performance metrics.
    """
    
    def __init__(self, event_bus):
        """Initialize the system health monitor.
        
        Args:
            event_bus: Event bus to subscribe to for monitoring events
        """
        self.event_bus = event_bus
        self.ingestion_events = []
        self.retrieval_events = []
        self.field_state_events = []
        self.window_state_events = []
        self.pattern_coherence_diffs = []
        self.field_state_diffs = {}
        self.response_times = []
        self.event_timestamps = {}
        
        # Subscribe to events
        self.event_bus.subscribe("pattern.detected", self._on_pattern_event)
        self.event_bus.subscribe("field.state.updated", self._on_field_state_event)
        self.event_bus.subscribe("window.state.changed", self._on_window_state_event)
    
    def _on_pattern_event(self, event):
        """Handle pattern events for health monitoring.
        
        Args:
            event: Pattern event to process
        """
        event_data = event.data
        direction = event_data.get("direction")
        pattern_id = event_data.get("pattern_id")
        pattern = event_data.get("pattern")
        
        # Record event timestamp
        now = datetime.now()
        event_key = f"pattern_{pattern_id}_{direction}"
        self.event_timestamps[event_key] = now
        
        # Track event by direction
        if direction == Direction.INGESTION.value:
            self.ingestion_events.append(event)
        elif direction == Direction.RETRIEVAL.value:
            self.retrieval_events.append(event)
            
            # Calculate response time if we have a matching ingestion event
            ingestion_key = f"pattern_{pattern_id}_{Direction.INGESTION.value}"
            if ingestion_key in self.event_timestamps:
                ingestion_time = self.event_timestamps[ingestion_key]
                response_time = (now - ingestion_time).total_seconds()
                self.response_times.append(response_time)
            
            # Calculate coherence differential if we have both patterns
            ingestion_pattern = next((e.data.get("pattern") for e in self.ingestion_events 
                                  if e.data.get("pattern_id") == pattern_id), None)
            if ingestion_pattern:
                coherence_diff = pattern.coherence - ingestion_pattern.coherence
                self.pattern_coherence_diffs.append({
                    "pattern_id": pattern_id,
                    "ingestion_coherence": ingestion_pattern.coherence,
                    "retrieval_coherence": pattern.coherence,
                    "diff": coherence_diff
                })
    
    def _on_field_state_event(self, event):
        """Handle field state events for health monitoring.
        
        Args:
            event: Field state event to process
        """
        self.field_state_events.append(event)
        
        event_data = event.data
        field_id = event_data.get("field_id")
        state = event_data.get("state", {})
        
        # Track field state changes
        if field_id not in self.field_state_diffs:
            self.field_state_diffs[field_id] = []
        
        self.field_state_diffs[field_id].append({
            "timestamp": datetime.now(),
            "coherence": state.get("coherence", 0.0),
            "stability": state.get("stability", 0.0),
            "density": state.get("density", 0.0),
            "potential_energy": state.get("potential_energy", 0.0)
        })
    
    def _on_window_state_event(self, event):
        """Handle window state events for health monitoring.
        
        Args:
            event: Window state event to process
        """
        self.window_state_events.append(event)
    
    def calculate_health_metrics(self):
        """Calculate system health metrics based on bidirectional flow differentials.
        
        Returns:
            Dictionary of health metrics
        """
        # Calculate average response time
        avg_response_time = sum(self.response_times) / len(self.response_times) if self.response_times else 0
        
        # Calculate coherence improvement
        avg_coherence_diff = sum(item["diff"] for item in self.pattern_coherence_diffs) / len(self.pattern_coherence_diffs) if self.pattern_coherence_diffs else 0
        
        # Calculate field state stability
        field_stability = {}
        for field_id, states in self.field_state_diffs.items():
            if len(states) > 1:
                # Calculate variance in coherence
                coherence_values = [state["coherence"] for state in states]
                coherence_variance = self._calculate_variance(coherence_values)
                
                # Calculate trend in potential energy
                potential_values = [state.get("potential_energy", 0.0) for state in states]
                potential_trend = self._calculate_trend(potential_values)
                
                field_stability[field_id] = {
                    "coherence_variance": coherence_variance,
                    "potential_trend": potential_trend
                }
        
        # Calculate overall system health score
        health_score = self._calculate_health_score(
            avg_response_time,
            avg_coherence_diff,
            field_stability
        )
        
        # Calculate feedback loop risk
        feedback_loop_risk = self._calculate_feedback_loop_risk()
        
        return {
            "avg_response_time": avg_response_time,
            "avg_coherence_improvement": avg_coherence_diff,
            "field_stability": field_stability,
            "health_score": health_score,
            "feedback_loop_risk": feedback_loop_risk,
            "pattern_evolution_count": len(self.retrieval_events),
            "field_state_update_count": len(self.field_state_events),
            "window_state_change_count": len(self.window_state_events)
        }
    
    def _calculate_variance(self, values):
        """Calculate variance of a list of values.
        
        Args:
            values: List of values to calculate variance for
            
        Returns:
            Variance of the values
        """
        if not values:
            return 0
        
        mean = sum(values) / len(values)
        return sum((x - mean) ** 2 for x in values) / len(values)
    
    def _calculate_trend(self, values):
        """Calculate trend (slope) of a list of values.
        
        Args:
            values: List of values to calculate trend for
            
        Returns:
            Trend (slope) of the values
        """
        if len(values) < 2:
            return 0
        
        # Simple linear regression slope
        x = list(range(len(values)))
        mean_x = sum(x) / len(x)
        mean_y = sum(values) / len(values)
        
        numerator = sum((x[i] - mean_x) * (values[i] - mean_y) for i in range(len(values)))
        denominator = sum((x[i] - mean_x) ** 2 for i in range(len(values)))
        
        return numerator / denominator if denominator != 0 else 0
    
    def _calculate_health_score(self, response_time, coherence_diff, field_stability):
        """Calculate overall system health score.
        
        Args:
            response_time: Average response time
            coherence_diff: Average coherence differential
            field_stability: Field stability metrics
            
        Returns:
            System health score (0-100)
        """
        # Response time score (lower is better)
        response_score = max(0, 100 - response_time * 20)  # Penalize for response time > 5 seconds
        
        # Coherence improvement score (higher is better)
        coherence_score = min(100, coherence_diff * 200)  # 0.5 improvement = 100 score
        
        # Field stability score (lower variance is better)
        stability_scores = []
        for field_id, metrics in field_stability.items():
            variance_score = max(0, 100 - metrics["coherence_variance"] * 500)  # Penalize high variance
            trend_score = min(100, (metrics["potential_trend"] + 0.1) * 500)  # Reward positive trends
            stability_scores.append((variance_score + trend_score) / 2)
        
        avg_stability_score = sum(stability_scores) / len(stability_scores) if stability_scores else 50
        
        # Overall health score (weighted average)
        return (response_score * 0.3 + coherence_score * 0.4 + avg_stability_score * 0.3)
    
    def _calculate_feedback_loop_risk(self):
        """Calculate risk of feedback loops based on event patterns.
        
        Returns:
            Feedback loop risk score (0-1)
        """
        # Count rapid back-and-forth events
        rapid_exchanges = 0
        for i in range(1, len(self.field_state_events)):
            prev_event = self.field_state_events[i-1]
            curr_event = self.field_state_events[i]
            
            prev_time = self.event_timestamps.get(f"field_{prev_event.data.get('field_id')}", datetime.now())
            curr_time = self.event_timestamps.get(f"field_{curr_event.data.get('field_id')}", datetime.now())
            
            # If events are close together, count as rapid exchange
            if (curr_time - prev_time).total_seconds() < 0.1:
                rapid_exchanges += 1
        
        # Calculate risk based on proportion of rapid exchanges
        if len(self.field_state_events) <= 1:
            return 0.0
        
        return min(1.0, rapid_exchanges / (len(self.field_state_events) - 1))
    
    def log_health_report(self):
        """Log a detailed health report based on the bidirectional flow differential."""
        metrics = self.calculate_health_metrics()
        
        logger.info("\n===== SYSTEM HEALTH REPORT =====")
        logger.info(f"Overall Health Score: {metrics['health_score']:.2f}/100")
        logger.info(f"Feedback Loop Risk: {metrics['feedback_loop_risk']:.2f}")
        logger.info(f"Average Response Time: {metrics['avg_response_time']:.4f} seconds")
        logger.info(f"Average Coherence Improvement: {metrics['avg_coherence_improvement']:.4f}")
        
        logger.info("\nPattern Evolution Analysis:")
        for diff in self.pattern_coherence_diffs:
            logger.info(f"  - Pattern {diff['pattern_id']}: {diff['ingestion_coherence']:.4f} → {diff['retrieval_coherence']:.4f} (Δ{diff['diff']:.4f})")
        
        logger.info("\nField Stability Analysis:")
        for field_id, metrics in metrics['field_stability'].items():
            logger.info(f"  - Field {field_id}:")
            logger.info(f"    * Coherence Variance: {metrics['coherence_variance']:.4f}")
            logger.info(f"    * Potential Energy Trend: {metrics['potential_trend']:.4f}")
        
        logger.info("\nEvent Counts:")
        logger.info(f"  - Pattern Evolution Events: {metrics['pattern_evolution_count']}")
        logger.info(f"  - Field State Updates: {metrics['field_state_update_count']}")
        logger.info(f"  - Window State Changes: {metrics['window_state_change_count']}")
        
        # Provide system health recommendations
        self._provide_health_recommendations(metrics)
        
        logger.info("================================\n")
    
    def _provide_health_recommendations(self, metrics):
        """Provide system health recommendations based on metrics.
        
        Args:
            metrics: System health metrics
        """
        logger.info("\nSystem Health Recommendations:")
        
        # Check for feedback loop risk
        if metrics['feedback_loop_risk'] > 0.3:
            logger.info("  ! ATTENTION: Elevated feedback loop risk detected")
            logger.info("    - Consider increasing the state change buffer cooldown period")
            logger.info("    - Review coherence threshold settings")
        
        # Check response time
        if metrics['avg_response_time'] > 2.0:
            logger.info("  ! ATTENTION: Slow pattern evolution response time")
            logger.info("    - Optimize vector-tonic processing")
            logger.info("    - Consider reducing pattern complexity")
        
        # Check coherence improvement
        if metrics['avg_coherence_improvement'] < 0.05:
            logger.info("  ! ATTENTION: Low coherence improvement in pattern evolution")
            logger.info("    - Review pattern evolution algorithms")
            logger.info("    - Consider adjusting constructive dissonance allowance")
        
        # Check field stability
        unstable_fields = [field_id for field_id, field_metrics in metrics['field_stability'].items() 
                         if field_metrics['coherence_variance'] > 0.1]
        if unstable_fields:
            logger.info("  ! ATTENTION: Unstable field states detected")
            logger.info(f"    - Fields with high variance: {', '.join(unstable_fields)}")
            logger.info("    - Consider adjusting field state update filtering")
        
        # Overall health score recommendations
        if metrics['health_score'] < 50:
            logger.info("  ! ATTENTION: System health score is low")
            logger.info("    - Comprehensive system review recommended")
            logger.info("    - Check for pattern oscillations and feedback loops")
        elif metrics['health_score'] > 80:
            logger.info("  ✓ System is operating within optimal parameters")
            logger.info("    - Continue monitoring for potential degradation")

# Run the test
if __name__ == "__main__":
    test = BidirectionalFlowE2ETest()
    asyncio.run(test.run_e2e_test())
