# Habitat Windsurf UI Course Handoff

**Document Date**: 2025-02-16T16:33:47-05:00

## Current Focus: Pattern-Aware RAG Integration Testing

### Testing Progress
1. **Completed Tests** âœ…
   - Sequential Foundation (Pattern extraction, ID assignment, Graph state)
   - Concurrent Operations (Pattern enhancement, State storage)
   - Pattern Feedback System
     - Attention smoothing with stability factors
     - Confidence decay and temporal evolution
     - Context updates and metadata handling

2. **In Progress** ðŸš§
   - Learning Window Controls
   - Stability Thresholds
   - Back Pressure Mechanisms

3. **Next Steps**
   - Event System Integration
   - Database Integration Tests
   - External Service Integration
   - Load Testing

### Key Considerations
- Maintaining backward compatibility
- Ensuring sequential foundation integrity
- Validating concurrent operations safety
- Monitoring system stability

---

## ðŸŒŸ Major Breakthroughs

### Neo4j to Pattern-Aware RAG Integration

1. **Graph Database Integration**
   ```python
   # src/habitat_evolution/visualization/test_visualization.py
   class TestPatternVisualizer:
       def export_pattern_graph_to_neo4j(self, patterns: List[PatternAdaptiveID], field: np.ndarray):
           """Export pattern graph with rich data embedding."""
           with self._neo4j_driver.session() as session:
               # Create pattern nodes
               for pattern in patterns:
                   node_data = pattern.to_dict()
                   session.run("""
                       CREATE (p:Pattern {
                           id: $id,
                           pattern_type: $pattern_type,
                           hazard_type: $hazard_type,
                           position_x: $pos_x,
                           position_y: $pos_y,
                           coherence: $coherence,
                           energy_state: $energy_state
                       })
                   """, node_data)

               # Create pattern relationships
               for pattern in patterns:
                   for target_id, relationships in pattern.relationships.items():
                       latest = sorted(relationships, key=lambda x: x['timestamp'])[-1]
                       session.run("""
                           MATCH (p1:Pattern {id: $source}), (p2:Pattern {id: $target})
                           CREATE (p1)-[:INTERACTS_WITH {
                               type: $type,
                               spatial_distance: $distance,
                               coherence_similarity: $similarity,
                               combined_strength: $strength
                           }]->(p2)
                       """, {
                           'source': pattern.id,
                           'target': target_id,
                           'type': latest['type'],
                           'metrics': latest['metrics']
                       })
   ```

2. **Pattern-Aware RAG Integration**
   ```python
   # src/tests/unified/PORT/core/pattern_aware_rag.py
   class PatternAwareRAG:
       async def process_with_patterns(self, query: str, context: Optional[Dict[str, Any]] = None):
           """Process query with pattern awareness and graph context."""
           # Extract patterns from Neo4j graph
           graph_patterns = await self._extract_graph_patterns()
           
           # Create embedding context with graph data
           embedding_context = EmbeddingContext(
               flow_state=self.emergence_flow.get_flow_state(),
               evolution_metrics=self._calculate_evolution_metrics(graph_patterns),
               pattern_context={"patterns": graph_patterns}
           )
           
           # Retrieve with graph-aware embeddings
           docs = await self._retrieve_with_graph_context(query, embedding_context)
           
           # Generate enhancement suggestions
           enhancements = await self._generate_pattern_enhancements(docs, graph_patterns)
           
           return docs, enhancements
   ```

3. **Key Components**
   - Neo4j graph database for pattern storage
   - Pattern-aware RAG controller
   - Graph-enhanced embeddings
   - Pattern enhancement pipeline
   - Connection Details:
     - Neo4j URL: bolt://localhost:7687
     - Browser: http://localhost:7474
     - Auth: neo4j/habitat123

4. **Next Steps**
   - Implement graph to RAG transformation
   - Enhance coherence-aware embeddings
   - Build pattern enhancement pipeline
   - Add cross-pattern relationship discovery
   - Optimize query performance
   - Implement caching strategy

### Social Pattern Service Integration

We've successfully implemented and integrated the social pattern service with the following key achievements:

1. **Social Pattern Service Implementation**
   ```python
   # src/habitat_evolution/social/services/social_pattern_service.py
   class SocialPatternService(PatternEvolutionService):
       """Social pattern evolution service."""
       
       async def track_practice_evolution(self, pattern_id: str, practice_data: Dict):
           # Calculate social metrics
           metrics = await self._calculate_practice_metrics(pattern_id, practice_data)
           
           # Update pattern state
           if metrics.practice_maturity >= PRACTICE_THRESHOLD:
               await self._evolution_manager.update_pattern_state(
                   pattern_id, 
                   {"state": PatternState.STABLE}
               )
               
           # Create practice relationships
           await self._update_practice_relationships(pattern_id)
           
           # Emit practice emergence event
           await self._event_bus.publish(Event.create(
               "social.practice.emerged",
               {"pattern_id": pattern_id, "metrics": metrics.to_dict()}
           ))
   ```

2. **Key Components**
   - Pattern-to-graph transformation pipeline
   - Rich data embedding in nodes
   - Relationship capture in edges
   - Dual-view visualization system
   - Neo4j integration for persistence:
     ```cypher
     # View all patterns and relationships
     MATCH (p:Pattern)-[r]->(f:FieldState)
     RETURN p, r, f

     # Query pattern evolution
     MATCH (p1:Pattern)-[r:EVOLVES_TO]->(p2:Pattern)
     WHERE p1.hazard_type = 'precipitation'
     RETURN p1, r, p2
     ```
   - Connection Details:
     - URL: bolt://localhost:7687
     - Browser: http://localhost:7474
     - Auth: neo4j/password

3. **Impact**
   - Enhanced pattern analysis through graph structures
   - Better evolution tracking over time
   - Improved cross-hazard relationship understanding
   - Rich query capabilities through Neo4j
   - Foundation for advanced RAG operations

## ðŸŒŸ Major Breakthroughs

### 1. Pattern Observation System
We've successfully implemented a neighbor-aware pattern observation system with climate risk focus:

1. **Multi-Modal Observation**
   - Wave mechanics for phase tracking
   - Field theory for gradient analysis
   - Flow dynamics for pattern interaction
   - Climate-specific attention filters

2. **Neighbor Context Management**
   - 8-direction spatial sampling
   - Distance-weighted observations
   - Gradient alignment detection
   - Pattern coherence tracking

3. **Climate Risk Integration**
   - Martha's Vineyard test case implementation
   - Extreme precipitation tracking (7.34" rainfall)
   - Drought condition monitoring (26% likelihood)
   - Wildfire danger assessment (94% increase)

4. **Pattern Analysis**
   - Strong local coherence detection
   - Organized climate pattern recognition
   - Cross-hazard interaction tracking
   - Adaptation opportunity identification
   - Turbulence damping for coherent patterns
   - Enhanced dissipation for incoherent patterns

### 2. Pattern Observation
We've discovered that pattern observation emerges naturally from field conditions:

1. **Back Pressure Mechanism**
   - Emerges from energy differentials between patterns
   - Higher energy patterns create back pressure on lower energy ones
   - Back pressure affects both observation and pattern behavior

2. **Observation Components**
   - Phase relationships (e.g. Ï€/4 phase difference)
   - Cross-pattern flow (bidirectional influence)
   - Field turbulence (affects observation clarity)
   - Energy state differences (creates observation pressure)

3. **Key Insight**
   Back pressure doesn't just resist - it creates an observation environment. Higher turbulence or energy differentials change how patterns are perceived, even if the patterns themselves remain unchanged.

See [PATTERN_REGULATION_BREAKTHROUGH.md](src/tests/unified/PORT/adaptive_core/pattern/PATTERN_REGULATION_BREAKTHROUGH.md) for complete technical details.

## Architectural Integration Guide

### Core System Architecture (`src/core/`)

1. **Field Services System**
   ```python
   # src/core/services/field/field_state_service.py
   class ConcreteFieldStateService:
       """Manages field state and stability."""
       
       def __init__(self, field_repository: FieldRepository, event_bus: EventBus):
           self.repository = field_repository
           self.event_bus = event_bus

       async def calculate_field_stability(self, field_id: str) -> float:
           """Calculate stability metric for a field."""
           state = await self.get_field_state(field_id)
           stability = calculate_field_stability(
               potential=state.potential,
               gradient=state.gradient,
               metadata=state.metadata
           )
           await self.event_bus.emit("field.stability.calculated", {...})
           return stability
   ```

2. **Gradient System**
   ```python
   # src/core/services/field/gradient_service.py
   class ConcreteGradientService:
       """Handles gradient calculations and flow dynamics."""
       
       async def calculate_gradient(self, field_id: str, position: Dict[str, float]) -> GradientVector:
           """Calculate gradient vector at position."""
           field_state = await self.repository.get_field_state(field_id)
           gradient_components = self._calculate_components(field_state, position)
           stability = self._calculate_gradient_stability(gradient_components, field_state.stability)
           await self.event_bus.emit("field.gradient.calculated", {...})
           return GradientVector(direction=gradient_components, magnitude=magnitude, stability=stability)
   ```

3. **Flow Dynamics System**
   ```python
   # src/core/services/field/flow_dynamics_service.py
   class ConcreteFlowDynamicsService:
       """Handles flow-related calculations and dynamics."""
       
       async def calculate_turbulence(self, field_id: str, position: Dict[str, float]) -> float:
           """Calculate turbulence at position."""
           gradient = await self.gradient_service.calculate_gradient(field_id, position)
           viscosity = await self.calculate_viscosity(field_id, position)
           reynolds = velocity * characteristic_length / viscosity
           turbulence = 1.0 - (1.0 / (1.0 + reynolds/5000))
           await self.event_bus.emit("field.turbulence.calculated", {...})
           return turbulence
   ```

4. **Pattern Evolution System**
   ```python
   # src/core/pattern_evolution.py
   class FieldDrivenPatternManager:
       """Manages pattern evolution through field-driven dynamics."""
       
       def __init__(self):
           self.gradient_analyzer = GradientAnalyzer()
           self.flow_controller = FlowController()
           self.pattern_store = PatternStore()

       async def evolve_patterns(self, field_state):
           """Evolves patterns based on field conditions."""
           gradients = self.gradient_analyzer.analyze(field_state)
           flow = self.flow_controller.calculate_flow(gradients)
           return await self._update_patterns(flow)
   ```

2. **Flow Management**
   ```python
   # src/core/flow/gradient_controller.py
   class GradientFlowController:
       """Controls pattern flow based on field gradients."""
       
       def calculate_flow(self, gradients):
           """Calculates flow metrics from field gradients."""
           coherence_flow = self._calculate_coherence_flow(gradients)
           energy_flow = self._calculate_energy_flow(gradients)
           return self._combine_flows(coherence_flow, energy_flow)
   ```

3. **Pattern Quality Analysis**
   ```python
   # src/core/quality/analyzer.py
   class PatternQualityAnalyzer:
       """Analyzes pattern quality through field lens."""
       
       def analyze_pattern(self, pattern, field_state):
           """Analyzes pattern quality in current field."""
           coherence = self._calculate_coherence(pattern, field_state)
           stability = self._assess_stability(coherence, field_state)
           return QualityMetrics(coherence, stability)
   ```

### Test Architecture (`src/tests/`)

1. **Field Services Test Suite**
   ```python
   # src/tests/core/services/field/test_field_state_service.py
   class TestFieldStateService:
       """Tests for field state service."""
       
       async def test_calculate_field_stability(self):
           """Test stability calculation with coherence validation."""
           state = await field_service.calculate_field_stability("test_field")
           assert 0.0 <= state.stability <= 1.0
           # Validate event emission
           event_bus.emit.assert_called_with("field.stability.calculated", {...})
   ```

2. **Flow Dynamics Test Suite**
   ```python
   # src/tests/core/services/field/test_flow_dynamics_service.py
   class TestFlowDynamicsService:
       """Tests for flow dynamics service."""
       
       @pytest.mark.parametrize("coherence,turbulence", [
           (0.2, 0.8),  # Incoherent pattern with high turbulence
           (0.8, 0.4),  # Coherent pattern with moderate turbulence
       ])
       async def test_pattern_stability_conditions(self, coherence, turbulence):
           """Test pattern stability under different conditions."""
           viscosity = await service.calculate_viscosity(field_id, position)
           if coherence < 0.5:  # Incoherent pattern
               assert viscosity > 0.8
           else:  # Coherent pattern
               assert viscosity < 0.5
   ```

3. **Core Test Suite**
   - `test_pattern_evolution.py`: Field-driven evolution tests
   - `test_flow_dynamics.py`: Gradient flow validation
   - `test_field_coupling.py`: Field-pattern interaction tests

2. **PORT Integration Tests**
   ```python
   # src/tests/unified/PORT/adaptive_core/tests/pattern/test_field_integration.py
   class TestFieldIntegration:
       """Tests field-driven pattern integration."""
       
       async def test_pattern_field_coupling(self):
           """Tests pattern-field coupling mechanics."""
           field = create_test_field()
           pattern = create_test_pattern()
           evolution = await evolve_with_field(pattern, field)
           assert evolution.coherence > 0.3
   ```

### Integration Points

1. **Field Services**
   - Field state management in `src/core/services/field/field_state_service.py`
   - Gradient calculations in `src/core/services/field/gradient_service.py`
   - Flow dynamics in `src/core/services/field/flow_dynamics_service.py`
   - Event emission for monitoring and tracking
   - Neo4j persistence layer

2. **Pattern Evolution**
   - Field gradient analysis in `src/core/pattern_evolution.py`
   - Flow dynamics in `src/core/flow/`
   - Quality metrics in `src/core/quality/`

2. **Testing Framework**
   - Core evolution tests in `src/tests/`
   - PORT integration in `src/tests/unified/PORT/`
   - Field coupling tests in both layers

3. **Visualization Layer**
   - Gradient visualization in `src/core/visualization/`
   - Flow rendering components
   - Pattern state indicators

## Recently Ported Core Modules

### Core Components
The following modules have been ported from the habitat_poc repository:

1. **Coherence Tracking**
   - File: `coherence_tracking.py`
   - Purpose: Light coherence assessment for structure-meaning alignment
   - Key features: Coherence metrics, assessment levels, warning flags

2. **Emergence Flow**
   - File: `emergence_flow.py`
   - Purpose: Pattern emergence and evolution tracking
   - Key features: Flow dynamics, pattern intersection analysis, coherence flow

3. **Pattern Flow**
   - File: `pattern_flow.py`
   - Purpose: Pattern flow types and analysis
   - Key features: Flow types, pattern matching, interface recognition

4. **Learning Windows**
   - File: `learning_windows.py`
   - Purpose: Learning windows interface for knowledge integration
   - Key features: Window registration, density analysis, coherence validation

5. **Pattern-Aware RAG**
   - File: `pattern_aware_rag.py`
   - Purpose: Pattern-aware RAG controller
   - Key features: Pattern extraction, coherence tracking, RAG enhancement

### Test Files
Corresponding test files have been ported and organized into:
- Core Tests: Flow emergence, learning windows, pattern evolution
- RAG Tests: Pattern-aware functionality
- Pattern Tests: Detection capabilities
- Meta Tests: Meta-learning and poly-agentic systems

### Important Notes
1. Tests follow interface-dependent flow dynamics
2. Coherence-adherence principles are key
3. LLM RAG interfaces require proper tuning
4. Pattern recognition uses dynamic thresholds

## Project Overview

Habitat Windsurf UI Course is an interactive visualization workshop focused on real-time network visualization and status tracking. The project demonstrates modern web development practices with a focus on user experience and error handling.

## Component Architecture

### Visualization Layer
- `network.js`: D3.js force-directed graph implementation
- Real-time node and link updates
- Interactive drag and zoom capabilities
- Stage-based filtering system

### Status System
- Real-time process tracking
- Glowing status indicators
- Step-by-step progress visualization
- Comprehensive error handling

### Backend Integration
- FastAPI REST endpoints
- WebSocket real-time updates
- MongoDB data persistence
- Robust error handling and status codes

## Developer Guides

### For Senior Developers
- Architecture focuses on modularity and maintainability
- Key extension points in network.js for additional visualization types
- Error handling system can be extended for new error types
- Performance considerations in WebSocket implementation
- Consider memory management for large datasets

### For Junior Developers
- Start with `main.js` to understand the application flow
- Status indicators in `network.js` show how to handle UI states
- Error handling patterns demonstrate good practices
- CSS shows modern styling techniques
- Follow existing patterns for new features

### For AI Agents
- Component boundaries are clearly defined
- Error states are explicitly handled
- Data structures are consistently formatted
- Status updates follow predictable patterns
- Documentation provides context for decisions

## Current Status

### Implemented Features
- [x] Network visualization with D3.js
- [x] Real-time status tracking
- [x] Error handling system
- [x] WebSocket integration
- [x] Dark theme and grid background

### Pending Tasks
- [ ] Performance optimization for large datasets
- [ ] Cross-browser testing
- [ ] Documentation updates
- [ ] Memory leak testing
- [ ] Load testing with WebSocket connections

## Next Development Phase: Climate Risk Pattern Evolution

### Overview
Implement dynamic pattern learning and coherence analysis for climate risk data, building on the initial implementation with `climate_risk_marthas_vineyard.txt` as source data.

### High-Level Steps

1. **Pattern Evolution System**
   - Semantic pattern extraction with emphasis detection
   - Temporal relationship tracking
   - Pattern evolution metrics
   - Coherence scoring system
   - Note: See `docs/PATTERN_EVOLUTION.md` for details

2. **Pattern Storage and Analysis**
   - Pattern-aware document schema in MongoDB
   - Evolution tracking endpoints in FastAPI
   - Coherence calculation service
   - Pattern relationship storage
   - Temporal context preservation

3. **Pattern Visualization**
   - Dynamic network graph for pattern relationships
   - Temporal evolution visualization
   - Coherence strength indicators
   - Pattern density visualization
   - Real-time evolution tracking

4. **Evolution Analysis Tools**
   - Pattern evolution tracking interface
   - Coherence analysis dashboard
   - Temporal relationship explorer
   - Pattern density analysis
   - Cross-document pattern viewer

5. **Testing and Validation**
   - Pattern extraction validation
   - Coherence calculation tests
   - Evolution tracking verification
   - Performance benchmarking
   - Cross-document pattern tests
   - Visualization rendering tests
   - Mock data validation

### Key Considerations
- Keep mock pipeline modular for easy replacement
- Document all assumptions about future NLP integration
- Maintain compatibility with habitat_evolution ID system
- Focus on visualization features that will remain relevant

### Internal Development (Not Part of Workshop)
A parallel development effort is underway to migrate and enhance core visualization components. This work is internal and separate from the workshop content.

## Required Reading
1. [POC Requirements](habitat_windsurf_ui_poc.md) - Core requirements and course structure
2. [Current State](STATE.md) - Project status and next steps

## Repository Structure
```
habitat-windsurf/
â”œâ”€â”€ docs/
â”œâ”€â”€ src/
â”œâ”€â”€ tests/
â””â”€â”€ notebooks/
```

## Development Setup

### Prerequisites
1. Python 3.11+
2. Docker and Docker Compose
3. MongoDB
4. Neo4j (optional)
5. Windsurf IDE installed
6. Git
7. Access to habitat_poc repository (for component migration)

### Local Environment Setup
```bash
# Clone repository
git clone https://github.com/your-org/habitat-windsurf.git
cd habitat-windsurf

# Start required services
docker-compose up -d mongodb neo4j

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows

# Install dependencies
pip install -r requirements.txt

# Run test suite
python -m pytest

# Start development server
uvicorn src.visualization.api.app:app --reload
```

### Configuration
1. Copy `.env.example` to `.env`
2. Update environment variables as needed:
   ```env
   WINDSURF_HOME=/path/to/windsurf
   HABITAT_POC_PATH=/path/to/habitat_poc
   MONGO_USERNAME=your_username
   MONGO_PASSWORD=your_password
   MONGO_HOST=localhost
   MONGO_PORT=27017
   NEO4J_USERNAME=neo4j
   NEO4J_PASSWORD=your_password
   NEO4J_HOST=localhost
   NEO4J_PORT=7687
   ```

### Verification Steps
1. Run `pytest tests/test_visualization.py` - should pass basic visualization tests
2. Open `notebooks/lesson_01/basics.ipynb` in Jupyter - should load without errors
3. Check GraphVisualizer initialization

## Current Progress

### Core Implementation
- GraphVisualizer with Plotly integration
- MongoDB integration with authentication
- Neo4j integration 
- WebSocket for real-time updates
- FastAPI REST endpoints
- Comprehensive test suite
- First lesson notebook (balanced approach)
- Documentation structure (collaborative)
- Workshop builder (hybrid implementation)

### Learning Approach
- Progressive complexity model
- Balanced user-agent interactions
- Hands-on exercises with agent support
- Clear learning objectives for each module

## Component Status
1. Core Visualization
   - GraphVisualizer (implemented with Plotly)
   - MongoDB Client (authentication enabled)
   - Neo4j Client (optional integration)
   - WebSocket Manager (real-time updates)
   - FastAPI Router (REST endpoints)
   - Agentic Builder (workshop automation)

2. Course Materials
   - Directory structure complete
   - Basic notebook implemented
   - Exercise templates ready
   - Advanced content pending

3. Testing
   - Basic test suite passing
   - Integration tests pending
   - Exercise validation pending

## Development Tasks

### Workshop Technical Stack (Current Release)

1. **Backend** (`src/backend/`)
   - FastAPI for REST and WebSocket
   - SQLAlchemy for ORM
   - Redis for real-time state
   - GraphQL for complex queries

2. **Frontend** (`src/frontend/`)
   - React with TypeScript
   - Plotly.js for visualization
   - TailwindCSS for styling
   - Apollo Client for GraphQL

3. **Infrastructure** (`infra/`)
   - Docker for containerization
   - Redis for pub/sub
   - PostgreSQL for persistence
   - Nginx for routing

### Workshop Development Environment (Current Release)

1. **Prerequisites**
   ```bash
   # Required software:
   python >= 3.9
   node >= 16.0
   docker >= 20.0
   redis >= 6.0
   ```

2. **Setup Commands**
   ```bash
   # Backend setup
   python -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   
   # Frontend setup
   cd frontend
   npm install
   ```

3. **Development Flow**
   ```bash
   # Start services
   docker-compose up -d     # Start infrastructure
   make dev-backend        # Start FastAPI
   make dev-frontend       # Start React
   
   # Development tools
   make lint              # Run linters
   make test              # Run tests
   make docs              # Generate docs
   ```

### Workshop Structure
The repository implements a balanced user-agent approach:

#### User-Driven Components
- Manual implementation exercises
- Code exploration tasks
- Custom feature development
- Testing and validation

#### Agent-Assisted Features
- Environment setup automation
- Code scaffolding
- Test suite generation
- Documentation updates

#### Collaborative Elements
- Interactive notebooks
- Guided implementations
- Code reviews
- Problem-solving sessions

To use the builder:
```bash
# Build workshop
python scripts/agentic/workshop_builder.py

# Clean up
python scripts/agentic/workshop_builder.py clean
```

### Senior Developer Focus
1. Architecture & Integration
   - Design WebSocket protocol for real-time updates
   - Plan component event system
   - Define scaling strategy
   - Establish security guidelines

2. Course Architecture
   - Design advanced lesson structure
   - Plan integration tutorials
   - Create architecture documentation

3. Code Quality
   - Set up code review process
   - Implement CI/CD for notebooks
   - Define performance metrics

### Junior Developer Focus
1. Feature Implementation
   - Add visualization customization options
   - Implement user interaction features
   - Create basic exercise notebooks

2. Testing & Documentation
   - Write additional unit tests
   - Create usage examples
   - Document common issues

3. Learning Path
   - Study existing components
   - Practice with notebook examples
   - Start with small enhancements

## Points of Contact
- Project Lead: [TBD]
- Technical Lead: [TBD]
- Course Instructor: [TBD]

## Development Guidelines

### Repository Structure
```
habitat-windsurf/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ container.py         # DI container
â”‚   â”‚   â””â”€â”€ visualization/       # Core components
â”‚   â”‚       â”œâ”€â”€ graph.py         # GraphVisualizer
â”‚   â”‚       â””â”€â”€ layout.py        # LayoutEngine
â”‚   â””â”€â”€ lessons/                 # Course modules
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â””â”€â”€ test_visualization.py
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ lessons/
â”‚       â””â”€â”€ 01_windsurf_basics.md
â””â”€â”€ notebooks/
    â”œâ”€â”€ templates/
    â”‚   â””â”€â”€ lesson_template.ipynb
    â”œâ”€â”€ lesson_01/
    â””â”€â”€ lesson_02/
```

### Testing Strategy
1. Component Tests
   - Basic initialization tests implemented
   - More tests to be added as components are developed

2. Integration Tests (Planned)
   - Component interactions
   - WebSocket communication
   - Graph visualization flow

### Known Issues & Solutions
1. Component Placeholders
   - GraphVisualizer and LayoutEngine are stubs
   - Implementation coming from habitat_poc

2. Environment Setup
   - Use provided virtual environment
   - Run tests to verify setup

### Development Workflow
1. Check current component status in STATE.md
2. Refer to POC requirements for implementation details
3. Follow test-driven development approach
4. Update documentation as components are implemented

## ðŸŽ¯ Social Pattern Research Value

Our investigation into social patterns has revealed a powerful new direction for Habitat's pattern evolution framework:

1. **Field Dynamics in Social Systems**
   - Social patterns emerge from field interactions
   - Community practices stabilize through coherence
   - Resource and knowledge flows shape pattern evolution

2. **Pattern Types**
   - Resource sharing networks (food, tools, skills)
   - Knowledge transmission patterns
   - Community practice formation
   - Environmental response networks

3. **Value Proposition**
   - Track emergence of stable social practices
   - Model community resilience patterns
   - Map resource and knowledge flows
   - Understand practice institutionalization

4. **Research Focus**
   - How individual actions become collective practices
   - Pattern stability and coherence in social systems
   - Field dynamics in community evolution
   - Practice formation and institutionalization

This research direction leverages Habitat's core strengths in:
- Field-based pattern detection
- Evolution tracking
- Coherence analysis
- Pattern visualization

## Handoff Checklist
- [ ] Repository access granted
- [ ] Development environment documented
- [ ] All documentation reviewed
- [ ] Initial requirements understood
- [ ] Next steps clearly defined
- [ ] Contact information shared
